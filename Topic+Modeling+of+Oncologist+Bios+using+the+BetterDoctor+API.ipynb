{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "doctors united states network 20 experience based credentials rated analysis nationwide depth holds distinction spears belzer goldberg chadha slivnick yeh\n",
      "Topic #1:\n",
      "oncology medicine patients hematology md licensed internal currently california minnesota medical specializes washington colorado specialist treat practices sees illinois treats\n",
      "Topic #2:\n",
      "menomonie osseo bloomer eau ochoa bayona husband claire farm medicina burns nacional nambudiri activity like outdoors rio faculade sul brunstein\n",
      "Topic #3:\n",
      "princeton andover red maple wing burnsville wyoming zumbrota ellsworth weisdorf batezini robbinsdale kosmo workman plymouth keralavarma nwaneri fujioka laramie claudio\n",
      "Topic #4:\n",
      "medical active history malpractice licenses background check passed screening automated addition license including successfully having holds clear looked elements status\n",
      "Topic #5:\n",
      "nebraska subbiah pudunagar thome omaha hoessly gul fairmont prague stephan papillion regina niguel birbal bhaskar laguna shanmuga monrovia popescu landisville\n",
      "Topic #6:\n",
      "jersey new graduate brunswick nevada course combinatorial ryan voorhees chemistry coll med endoscopy asge raj burkhardt cline chippewa plainfield doyle\n",
      "Topic #7:\n",
      "medical university oncology medicine center hematology degree american cancer school clinical internal received texas college society board completed fellowship graduated\n",
      "Topic #8:\n",
      "surgery surgical iowa mckenzie liver pancreas laparoscopic hepatobiliary surgeon amini filho costa colon invasive minimally ducts robotic bile hagin tumors\n",
      "Topic #9:\n",
      "cancer patients care treatment clinical time research breast trials family children new cancers therapies leukemia malignant development enjoys work patient\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "api_key = '8d0c5c7411a969ae233ee34d47b1784c'\n",
    "base_url = \"https://api.betterdoctor.com/2016-03-01/doctors?specialty_uid=oncologist&location=\"\n",
    "rest_url = \",100&limit=100&user_key=\" + api_key\n",
    "\n",
    "# curated list of lat/long of top-10 cities in USA\n",
    "nyc = (40.71,-74.00)\n",
    "sf = (37.77, -122.42)\n",
    "dc = (38.91, -77.03)\n",
    "boston = (42.36, -71.06)\n",
    "seattle = (47.61, -122.33)\n",
    "chicago = (41.88, -87.63)\n",
    "austin = (30.27, -97.74)\n",
    "la = (34.05,-118.24)\n",
    "denver = (39.74,-104.99)\n",
    "minn = (44.98, -93.26)\n",
    "\n",
    "top10cities = [nyc,sf,dc,boston,seattle,chicago,austin,la,denver,minn]\n",
    "bios = []\n",
    "\n",
    "for city in top10cities:\n",
    "    time.sleep(5)\n",
    "    link = base_url + str(city[0]) + \",\" + str(city[1]) + rest_url    \n",
    "    jsonstr = urllib.request.urlopen(link).read().decode(\"utf8\")\n",
    "    data = json.loads(jsonstr)['data']\n",
    "\n",
    "    for index in range(len(data)):        \n",
    "        bio = data[index]['profile']['bio']\n",
    "        for s in bio.split(\".\\n\\n\"):\n",
    "            bios.append(s)\n",
    "            \n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "\n",
    "# Load the doctor bios, vectorize it. \n",
    "data_samples = bios\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(stop_words='english', max_df=0.95)\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "lda = LatentDirichletAllocation(n_topics=10, max_iter=10,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "lda.fit(tf)\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 20) #top 20 words per topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Dirichlet allocation is an automatic topic discovery algorithm first described in a paper published in thhe Journal of Machine Learning Research by Dr. Blei in 2003. \n",
    "For example, in a newspaper, the topics might be Entertainment, Sports, Politics, Classifieds...\n",
    "Each topic would then have a list of top-20 words.\n",
    "\n",
    "Suppose we wish to discover what topics describe the world of oncology.\n",
    "\n",
    "Using the BetterDoctor API, we obtain a set of 100 doctors in the surrounding 100 mile radius of a given lat/long location. To obtain a fairly distributed set of oncologists, we look up the locations of the top-10 cities in the USA. We thus obtain 10 times 100 = 1000 doctor profiles. These are extremely rich profiles with insurances, practices, addresses, phone numbers, degrees etc. We narrow in on the doctor's bio, which describes each doctor succintly in a para. We split each bio into multiple sentences. Now we have a giant corpus of sentences that describe what oncologists do.\n",
    "\n",
    "We use LDA to extract topics from this corpus.\n",
    "But how does LDA perform this discovery?\n",
    "\n",
    "LDA is a bag-of-words model.\n",
    "LDA represents documents as topic mixtures, that spit out words with certain probabilities. \n",
    "It assumes that documents are produced like so -\n",
    "Suppose you write a bio, you\n",
    "a. Decide on the number of words N the bio has, according to a Poisson distribution.\n",
    "b. Choose a topic mixture for the bio according to a Dirichlet distribution over a fixed set of K topics. \n",
    "Say we pick 12 words in a bio. \n",
    "\n",
    "We decide \n",
    "1/3 of the bio is about the doctor's credentials, \n",
    "1/3 about the locations where he practiced, and \n",
    "1/3 about what kind of diseases he specialises in.\n",
    "\n",
    "So picking a topic has 33% probability in the multinomial distribution of topics.\n",
    "Within a topic, we have a 25% probability of picking 1 of 4 words.\n",
    "Thus, each topic is probabilistically generated.\n",
    "\n",
    "Assuming this generative model for a collection of documents, LDA then tries to backtrack from the documents to find a set of topics that are likely to have generated the collection.\n",
    "\n",
    "Learning\n",
    "\n",
    "Now we have a set of bios. We choose a fixed number say 10 topics to automatically discover. LDA uses collapsed Gibbs sampling to discover the topic representation of each of these ten topics.\n",
    "\n",
    "LDA goes through each bio & randomly assigns each word in the bio to one of the 10 topics.\n",
    "\n",
    "This random assignment already gives you both topic representations of all the bios and word distributions of all the topics (albeit not very good ones).\n",
    "T improve on them, for each bio b,\n",
    "go through each word w in b…\n",
    "And for each topic t, compute two things: \n",
    "a) p(topic t | bio b) = the proportion of words in b that are currently assigned to topic t, \n",
    "b) p(word w | topic t) = the proportion of assignments to topic t over all bios that come from this word w.\n",
    "\n",
    "Reassign w a new topic, where we choose topic t with probability p(topic t | bio b) * p(word w | topic t)\n",
    "\n",
    "According to our generative model, this is essentially the probability that topic t generated word w, so it makes sense that we resample the current word’s topic with this probability. We’re assuming that all topic assignments except for the current word in question are correct, and then updating the assignment of the current word using our model of how documents are generated. After repeating the previous step a large number of times, we eventually reach a roughly steady state where all assignments are pretty good. \n",
    "\n",
    "So we use these assignments to estimate the topic mixtures of each document (by counting the proportion of words assigned to each topic within that document) and the words associated to each topic (by counting the proportion of words assigned to each topic overall).\n",
    "\n",
    "Let's examine our results:\n",
    "TOPIC 1 - DESCRIBES ONCOLOGY, STATES\n",
    "Topic 1:\n",
    "oncology medicine patients hematology md licensed internal currently california minnesota medical specializes washington colorado specialist treat practices sees illinois treats\n",
    "\n",
    "Topic 2, 3,5,6 - PLACES, PEOPLE\n",
    "Topic 2:\n",
    "menomonie osseo bloomer eau ochoa bayona husband claire farm medicina burns nacional nambudiri activity like outdoors rio faculade sul brunstein\n",
    "Topic 3:\n",
    "princeton andover red maple wing burnsville wyoming zumbrota ellsworth weisdorf batezini robbinsdale kosmo workman plymouth keralavarma nwaneri fujioka laramie claudio\n",
    "Topic 5:\n",
    "nebraska subbiah pudunagar thome omaha hoessly gul fairmont prague stephan papillion regina niguel birbal bhaskar laguna shanmuga monrovia popescu landisville\n",
    "Topic 6:\n",
    "jersey new graduate brunswick nevada course combinatorial ryan voorhees chemistry coll med endoscopy asge raj burkhardt cline chippewa plainfield doyle\n",
    "\n",
    "Topic 0 - CREDENTIALS\n",
    "doctors united states network 20 experience based credentials rated analysis nationwide depth holds distinction spears belzer goldberg chadha slivnick yeh\n",
    "\n",
    "Topic 4 - LICENSES\n",
    "medical active history malpractice licenses background check passed screening automated addition license including successfully having holds clear looked elements status\n",
    "\n",
    "Topic 7 - SCHOOLS\n",
    "medical university oncology medicine center hematology degree american cancer school clinical internal received texas college society board completed fellowship graduated\n",
    "\n",
    "Topic 8 - ANATOMY\n",
    "surgery surgical iowa mckenzie liver pancreas laparoscopic hepatobiliary surgeon amini filho costa colon invasive minimally ducts robotic bile hagin tumors\n",
    "\n",
    "Topic 9 - CARE\n",
    "cancer patients care treatment clinical time research breast trials family children new cancers therapies leukemia malignant development enjoys work patient"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
